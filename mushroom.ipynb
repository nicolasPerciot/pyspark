{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"Linear-Regression-California-Housing\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mush = os.path.join(os.path.abspath(''), 'mushrooms.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mush = spark.read.csv(path_mush,inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-----------+---------+-------+----+---------------+------------+---------+----------+-----------+----------+------------------------+------------------------+----------------------+----------------------+---------+----------+-----------+---------+-----------------+----------+-------+\n",
      "|class|cap-shape|cap-surface|cap-color|bruises|odor|gill-attachment|gill-spacing|gill-size|gill-color|stalk-shape|stalk-root|stalk-surface-above-ring|stalk-surface-below-ring|stalk-color-above-ring|stalk-color-below-ring|veil-type|veil-color|ring-number|ring-type|spore-print-color|population|habitat|\n",
      "+-----+---------+-----------+---------+-------+----+---------------+------------+---------+----------+-----------+----------+------------------------+------------------------+----------------------+----------------------+---------+----------+-----------+---------+-----------------+----------+-------+\n",
      "|    p|        x|          s|        n|      t|   p|              f|           c|        n|         k|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         s|      u|\n",
      "|    e|        x|          s|        y|      t|   a|              f|           c|        b|         k|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         n|      g|\n",
      "|    e|        b|          s|        w|      t|   l|              f|           c|        b|         n|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         n|      m|\n",
      "|    p|        x|          y|        w|      t|   p|              f|           c|        n|         n|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         s|      u|\n",
      "|    e|        x|          s|        g|      f|   n|              f|           w|        b|         k|          t|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        e|                n|         a|      g|\n",
      "+-----+---------+-----------+---------+-------+----+---------------+------------+---------+----------+-----------+----------+------------------------+------------------------+----------------------+----------------------+---------+----------+-----------+---------+-----------------+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_mush.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "categorical_columns = df_mush.columns\n",
    "\n",
    "for column in categorical_columns:\n",
    "    \n",
    "    stringIndexer = StringIndexer(inputCol = column, outputCol = column+\"_encoded\").fit(df_mush)\n",
    "    df_mush = stringIndexer.transform(df_mush)\n",
    "    \n",
    "    df_mush = df_mush.withColumn(column+\"_encoded\", df_mush[column+\"_encoded\"].cast('int'))\n",
    "    \n",
    "df_mush =  df_mush.select([col + '_encoded' for col in categorical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+-------------------+-----------------+---------------+------------+-----------------------+--------------------+-----------------+------------------+-------------------+------------------+--------------------------------+--------------------------------+------------------------------+------------------------------+-----------------+------------------+-------------------+-----------------+-------------------------+------------------+---------------+\n",
      "|class_encoded|cap-shape_encoded|cap-surface_encoded|cap-color_encoded|bruises_encoded|odor_encoded|gill-attachment_encoded|gill-spacing_encoded|gill-size_encoded|gill-color_encoded|stalk-shape_encoded|stalk-root_encoded|stalk-surface-above-ring_encoded|stalk-surface-below-ring_encoded|stalk-color-above-ring_encoded|stalk-color-below-ring_encoded|veil-type_encoded|veil-color_encoded|ring-number_encoded|ring-type_encoded|spore-print-color_encoded|population_encoded|habitat_encoded|\n",
      "+-------------+-----------------+-------------------+-----------------+---------------+------------+-----------------------+--------------------+-----------------+------------------+-------------------+------------------+--------------------------------+--------------------------------+------------------------------+------------------------------+-----------------+------------------+-------------------+-----------------+-------------------------+------------------+---------------+\n",
      "|            1|                0|                  1|                0|              1|           6|                      0|                   0|                1|                 7|                  1|                 2|                               0|                               0|                             0|                             0|                0|                 0|                  0|                0|                        2|                 2|              4|\n",
      "|            0|                0|                  1|                3|              1|           4|                      0|                   0|                0|                 7|                  1|                 3|                               0|                               0|                             0|                             0|                0|                 0|                  0|                0|                        1|                 3|              1|\n",
      "|            0|                3|                  1|                4|              1|           5|                      0|                   0|                0|                 3|                  1|                 3|                               0|                               0|                             0|                             0|                0|                 0|                  0|                0|                        1|                 3|              5|\n",
      "|            1|                0|                  0|                4|              1|           6|                      0|                   0|                1|                 3|                  1|                 2|                               0|                               0|                             0|                             0|                0|                 0|                  0|                0|                        2|                 2|              4|\n",
      "|            0|                0|                  1|                1|              0|           0|                      0|                   1|                0|                 7|                  0|                 2|                               0|                               0|                             0|                             0|                0|                 0|                  0|                1|                        1|                 4|              1|\n",
      "+-------------+-----------------+-------------------+-----------------+---------------+------------+-----------------------+--------------------+-----------------+------------------+-------------------+------------------+--------------------------------+--------------------------------+------------------------------+------------------------------+-----------------+------------------+-------------------+-----------------+-------------------------+------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_mush.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col = df_mush.columns\n",
    "df_col.remove('class_encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "featureAssembler = VectorAssembler(inputCols=df_col, outputCol=\"features\")\n",
    "\n",
    "output = featureAssembler.transform(df_mush)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.select(\"features\", \"class_encoded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = output.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6471"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'class_encoded', maxDepth = 3)\n",
    "# dtModel = dt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = dtModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "# # Create both evaluators\n",
    "# evaluatorMulti = MulticlassClassificationEvaluator(labelCol=\"class_encoded\", predictionCol=\"prediction\")\n",
    "# evaluator = BinaryClassificationEvaluator(labelCol=\"class_encoded\", rawPredictionCol=\"prediction\", metricName='areaUnderROC')\n",
    "\n",
    "# # Make predicitons\n",
    "# predictionAndTarget = dtModel.transform(test).select(\"class_encoded\", \"prediction\")\n",
    "\n",
    "# # Get metrics\n",
    "# acc = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"accuracy\"})\n",
    "# f1 = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"f1\"})\n",
    "# weightedPrecision = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"weightedPrecision\"})\n",
    "# weightedRecall = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"weightedRecall\"})\n",
    "# auc = evaluator.evaluate(predictionAndTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Accuracy         : ' + str(acc))\n",
    "# print('F1 score         : ' + str(f1))\n",
    "# print('Precision        : ' + str(weightedPrecision))\n",
    "# print('Recall           : ' + str(weightedRecall))\n",
    "# print('Area Under ROC   : ' + str(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "def train_test_model(model, train, test) :\n",
    "    \n",
    "    model_train = model.fit(train)\n",
    "    \n",
    "    # predictions = model_train.transform(test)\n",
    "\n",
    "    # Create both evaluators\n",
    "    evaluatorMulti      = MulticlassClassificationEvaluator(labelCol=\"class_encoded\", predictionCol=\"prediction\")\n",
    "    evaluator           = BinaryClassificationEvaluator(labelCol=\"class_encoded\", rawPredictionCol=\"prediction\", metricName='areaUnderROC')\n",
    "\n",
    "    # Make predicitons\n",
    "    predictionAndTarget = dtModel.transform(test).select(\"class_encoded\", \"prediction\")\n",
    "\n",
    "    # Get metrics\n",
    "    acc                 = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"accuracy\"})\n",
    "    f1                  = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"f1\"})\n",
    "    weightedPrecision   = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"weightedPrecision\"})\n",
    "    weightedRecall      = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"weightedRecall\"})\n",
    "    auc                 = evaluator.evaluate(predictionAndTarget)\n",
    "    \n",
    "    \n",
    "    print('Accuracy         : ' + str(acc))\n",
    "    print('F1 score         : ' + str(f1))\n",
    "    print('Precision        : ' + str(weightedPrecision))\n",
    "    print('Recall           : ' + str(weightedRecall))\n",
    "    print('Area Under ROC   : ' + str(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy         : 0.9832946635730858\n",
      "F1 score         : 0.9832917154116472\n",
      "Precision        : 0.9833257285904247\n",
      "Recall           : 0.9832946635730859\n",
      "Area Under ROC   : 0.9831149229774084\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt_mod = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'class_encoded', maxDepth = 3)\n",
    "\n",
    "train_test_model(dt_mod, train, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
